{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "KGEvFBH4gU1u",
   "metadata": {
    "id": "KGEvFBH4gU1u"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dimitarpg13/rag_architectures_and_concepts/blob/main/src/examples/langchain/mongo_cache_memory/mongodb_langchain_cache_memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b333e6",
   "metadata": {
    "id": "70b333e6"
   },
   "source": [
    "[![View Article](https://img.shields.io/badge/View%20Article-blue)](https://www.mongodb.com/developer/products/atlas/advanced-rag-langchain-mongodb/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84a72ea",
   "metadata": {
    "id": "d84a72ea"
   },
   "source": [
    "# Adding Semantic Caching and Memory to your RAG Application using MongoDB and LangChain\n",
    "\n",
    "In this notebook, we will see how to use the new MongoDBCache and MongoDBChatMessageHistory in your RAG application.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65527202",
   "metadata": {
    "id": "65527202"
   },
   "source": [
    "## Step 1: Install required libraries\n",
    "\n",
    "- **datasets**: Python library to get access to datasets available on Hugging Face Hub\n",
    "\n",
    "- **langchain**: Python toolkit for LangChain\n",
    "\n",
    "- **langchain-mongodb**: Python package to use MongoDB as a vector store, semantic cache, chat history store etc. in LangChain\n",
    "\n",
    "- **langchain-openai**: Python package to use OpenAI models with LangChain\n",
    "\n",
    "- **pymongo**: Python toolkit for MongoDB\n",
    "\n",
    "- **pandas**: Python library for data analysis, exploration, and manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbc22fa4",
   "metadata": {
    "id": "cbc22fa4"
   },
   "outputs": [],
   "source": [
    "! pip install -qU datasets langchain langchain-mongodb langchain-openai pymongo pandas dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c41e87",
   "metadata": {
    "id": "39c41e87"
   },
   "source": [
    "## Step 2: Setup pre-requisites\n",
    "\n",
    "* Set the MongoDB connection string. Follow the steps [here](https://www.mongodb.com/docs/manual/reference/connection-string/) to get the connection string from the Atlas UI.\n",
    "\n",
    "* Set the OpenAI API key. Steps to obtain an API key as [here](https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b56412ae",
   "metadata": {
    "id": "b56412ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16a20d7a",
   "metadata": {
    "id": "16a20d7a"
   },
   "outputs": [],
   "source": [
    "_set_env(\"MONGODB_URI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "978682d4",
   "metadata": {
    "id": "978682d4"
   },
   "outputs": [],
   "source": [
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "606081c5",
   "metadata": {
    "id": "606081c5"
   },
   "outputs": [],
   "source": [
    "# Optional-- If you want to enable Langsmith -- good for debugging\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "_set_env(\"LANGSMITH_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b8302c",
   "metadata": {
    "id": "f6b8302c"
   },
   "source": [
    "## Step 3: Download the dataset\n",
    "\n",
    "We will be using MongoDB's [embedded_movies](https://huggingface.co/datasets/MongoDB/embedded_movies) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a3433a6",
   "metadata": {
    "id": "1a3433a6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aee5311b",
   "metadata": {
    "id": "aee5311b"
   },
   "outputs": [],
   "source": [
    "# Ensure you have an HF_TOKEN in your development environment:\n",
    "# access tokens can be created or copied from the Hugging Face platform (https://huggingface.co/docs/hub/en/security-tokens)\n",
    "\n",
    "# Load MongoDB's embedded_movies dataset from Hugging Face\n",
    "# https://huggingface.co/datasets/MongoDB/airbnb_embeddings\n",
    "\n",
    "data = load_dataset(\"MongoDB/embedded_movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d630a26",
   "metadata": {
    "id": "1d630a26"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f94f43",
   "metadata": {
    "id": "a1f94f43"
   },
   "source": [
    "## Step 4: Data analysis\n",
    "\n",
    "Make sure length of the dataset is what we expect, drop Nones etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b276df71",
   "metadata": {
    "id": "b276df71"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plot</th>\n",
       "      <th>runtime</th>\n",
       "      <th>genres</th>\n",
       "      <th>fullplot</th>\n",
       "      <th>directors</th>\n",
       "      <th>writers</th>\n",
       "      <th>countries</th>\n",
       "      <th>poster</th>\n",
       "      <th>languages</th>\n",
       "      <th>cast</th>\n",
       "      <th>title</th>\n",
       "      <th>num_mflix_comments</th>\n",
       "      <th>rated</th>\n",
       "      <th>imdb</th>\n",
       "      <th>awards</th>\n",
       "      <th>type</th>\n",
       "      <th>metacritic</th>\n",
       "      <th>plot_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Young Pauline is left a lot of money when her ...</td>\n",
       "      <td>199.0</td>\n",
       "      <td>[Action]</td>\n",
       "      <td>Young Pauline is left a lot of money when her ...</td>\n",
       "      <td>[Louis J. Gasnier, Donald MacKenzie]</td>\n",
       "      <td>[Charles W. Goddard (screenplay), Basil Dickey...</td>\n",
       "      <td>[USA]</td>\n",
       "      <td>https://m.media-amazon.com/images/M/MV5BMzgxOD...</td>\n",
       "      <td>[English]</td>\n",
       "      <td>[Pearl White, Crane Wilbur, Paul Panzer, Edwar...</td>\n",
       "      <td>The Perils of Pauline</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>{'id': 4465, 'rating': 7.6, 'votes': 744}</td>\n",
       "      <td>{'nominations': 0, 'text': '1 win.', 'wins': 1}</td>\n",
       "      <td>movie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0007293965299999999, -0.026834568000000003,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                plot  runtime    genres  \\\n",
       "0  Young Pauline is left a lot of money when her ...    199.0  [Action]   \n",
       "\n",
       "                                            fullplot  \\\n",
       "0  Young Pauline is left a lot of money when her ...   \n",
       "\n",
       "                              directors  \\\n",
       "0  [Louis J. Gasnier, Donald MacKenzie]   \n",
       "\n",
       "                                             writers countries  \\\n",
       "0  [Charles W. Goddard (screenplay), Basil Dickey...     [USA]   \n",
       "\n",
       "                                              poster  languages  \\\n",
       "0  https://m.media-amazon.com/images/M/MV5BMzgxOD...  [English]   \n",
       "\n",
       "                                                cast                  title  \\\n",
       "0  [Pearl White, Crane Wilbur, Paul Panzer, Edwar...  The Perils of Pauline   \n",
       "\n",
       "   num_mflix_comments rated                                       imdb  \\\n",
       "0                   0  None  {'id': 4465, 'rating': 7.6, 'votes': 744}   \n",
       "\n",
       "                                            awards   type  metacritic  \\\n",
       "0  {'nominations': 0, 'text': '1 win.', 'wins': 1}  movie         NaN   \n",
       "\n",
       "                                      plot_embedding  \n",
       "0  [0.0007293965299999999, -0.026834568000000003,...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previewing the contents of the data\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22ab375d",
   "metadata": {
    "id": "22ab375d"
   },
   "outputs": [],
   "source": [
    "# Only keep records where the fullplot field is not null\n",
    "df = df[df[\"fullplot\"].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fceed99a",
   "metadata": {
    "id": "fceed99a"
   },
   "outputs": [],
   "source": [
    "# Renaming the embedding field to \"embedding\" -- required by LangChain\n",
    "df.rename(columns={\"plot_embedding\": \"embedding\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedec13a",
   "metadata": {
    "id": "aedec13a"
   },
   "source": [
    "## Step 5: Create a simple RAG chain using MongoDB as the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11d292f3",
   "metadata": {
    "id": "11d292f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mongodb+srv://dimitarpg13:mechodish13@cluster0.4j6alsy.mongodb.net/\n"
     ]
    }
   ],
   "source": [
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "from pymongo import MongoClient\n",
    "\n",
    "\n",
    "# Initialize MongoDB python client\n",
    "client = MongoClient(os.environ[\"MONGODB_URI\"], appname=\"devrel.content.python\")\n",
    "\n",
    "DB_NAME = \"langchain_chatbot\"\n",
    "COLLECTION_NAME = \"data\"\n",
    "ATLAS_VECTOR_SEARCH_INDEX_NAME = \"vector_index\"\n",
    "collection = client[DB_NAME][COLLECTION_NAME]\n",
    "print(os.environ[\"MONGODB_URI\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8292d53",
   "metadata": {
    "id": "d8292d53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeleteResult({'n': 1452, 'electionId': ObjectId('7fffffff0000000000000232'), 'opTime': {'ts': Timestamp(1752872454, 164), 't': 562}, 'ok': 1.0, '$clusterTime': {'clusterTime': Timestamp(1752872454, 166), 'signature': {'hash': b'\\x83\\x04\\x0ca\\x9b\\xb7\\xddJ\\x05z\\x84\\xbf\\xecu\\xae\\x00\"\\x0e\\x0ci', 'keyId': 7470231751734853634}}, 'operationTime': Timestamp(1752872454, 164)}, acknowledged=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete any existing records in the collection\n",
    "collection.delete_many({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36c68914",
   "metadata": {
    "id": "36c68914"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data ingestion into MongoDB completed\n"
     ]
    }
   ],
   "source": [
    "# Data Ingestion\n",
    "records = df.to_dict(\"records\")\n",
    "collection.insert_many(records)\n",
    "\n",
    "print(\"Data ingestion into MongoDB completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbfca0b8",
   "metadata": {
    "id": "cbfca0b8"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Using the text-embedding-ada-002 since that's what was used to create embeddings in the movies dataset\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"], model=\"text-embedding-ada-002\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "798e176c",
   "metadata": {
    "id": "798e176c"
   },
   "outputs": [],
   "source": [
    "# Vector Store Creation\n",
    "vector_store = MongoDBAtlasVectorSearch.from_connection_string(\n",
    "    connection_string=os.environ[\"MONGODB_URI\"],\n",
    "    namespace=DB_NAME + \".\" + COLLECTION_NAME,\n",
    "    embedding=embeddings,\n",
    "    index_name=ATLAS_VECTOR_SEARCH_INDEX_NAME,\n",
    "    text_key=\"fullplot\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c71cd087",
   "metadata": {
    "id": "c71cd087"
   },
   "outputs": [],
   "source": [
    "# Using the MongoDB vector store as a retriever in a RAG chain\n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6588cd3",
   "metadata": {
    "id": "b6588cd3"
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Generate context using the retriever, and pass the user question through\n",
    "retrieve = {\n",
    "    \"context\": retriever | (lambda docs: \"\\n\\n\".join([d.page_content for d in docs])),\n",
    "    \"question\": RunnablePassthrough(),\n",
    "}\n",
    "template = \"\"\"Answer the question based only on the following context: \\\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "# Defining the chat prompt\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "# Defining the model to be used for chat completion\n",
    "model = ChatOpenAI(temperature=0, openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "# Parse output as a string\n",
    "parse_output = StrOutputParser()\n",
    "\n",
    "# Naive RAG chain\n",
    "naive_rag_chain = retrieve | prompt | model | parse_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaae21f5",
   "metadata": {
    "id": "aaae21f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A feel-good comedy like \"The Princess Bride\" would be a great choice to watch when feeling sad.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_rag_chain.invoke(\"What is the best movie to watch when sad?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f929ef",
   "metadata": {
    "id": "75f929ef"
   },
   "source": [
    "## Step 6: Create a RAG chain with chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94e7bd4a",
   "metadata": {
    "id": "94e7bd4a"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_mongodb.chat_message_histories import MongoDBChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bb30860",
   "metadata": {
    "id": "5bb30860"
   },
   "outputs": [],
   "source": [
    "def get_session_history(session_id: str) -> MongoDBChatMessageHistory:\n",
    "    return MongoDBChatMessageHistory(\n",
    "        os.environ[\"MONGODB_URI\"], session_id, database_name=DB_NAME, collection_name=\"history\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f51d0f35",
   "metadata": {
    "id": "f51d0f35"
   },
   "outputs": [],
   "source": [
    "# Given a follow-up question and history, create a standalone question\n",
    "standalone_system_prompt = \"\"\"\n",
    "Given a chat history and a follow-up question, rephrase the follow-up question to be a standalone question. \\\n",
    "Do NOT answer the question, just reformulate it if needed, otherwise return it as is. \\\n",
    "Only return the final standalone question. \\\n",
    "\"\"\"\n",
    "standalone_question_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", standalone_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_chain = standalone_question_prompt | model | parse_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3ef3354",
   "metadata": {
    "id": "f3ef3354"
   },
   "outputs": [],
   "source": [
    "# Generate context by passing output of the question_chain i.e. the standalone question to the retriever\n",
    "retriever_chain = RunnablePassthrough.assign(\n",
    "    context=question_chain\n",
    "    | retriever\n",
    "    | (lambda docs: \"\\n\\n\".join([d.page_content for d in docs]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5afb7345",
   "metadata": {
    "id": "5afb7345"
   },
   "outputs": [],
   "source": [
    "# Create a prompt that includes the context, history and the follow-up question\n",
    "rag_system_prompt = \"\"\"Answer the question based only on the following context: \\\n",
    "{context}\n",
    "\"\"\"\n",
    "rag_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", rag_system_prompt),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f95f47d0",
   "metadata": {
    "id": "f95f47d0"
   },
   "outputs": [],
   "source": [
    "# RAG chain\n",
    "rag_chain = retriever_chain | rag_prompt | model | parse_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9618d395",
   "metadata": {
    "id": "9618d395"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A good movie to watch when feeling sad is \"Forrest Gump.\" This classic film follows the life of a kind-hearted man who experiences various ups and downs, showcasing themes of resilience, love, and the beauty of life\\'s simple moments. It\\'s a heartwarming and uplifting movie that can provide comfort and perspective during tough times.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RAG chain with history\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n",
    "with_message_history.invoke(\n",
    "    {\"question\": \"What is the best movie to watch when sad?\"},\n",
    "    {\"configurable\": {\"session_id\": \"1\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e3080d1",
   "metadata": {
    "id": "6e3080d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Another good movie to watch when feeling sad is \"La La Land.\" This musical film tells the story of a jazz musician and an aspiring actress who fall in love while pursuing their dreams in Los Angeles. With its beautiful cinematography, catchy music, and heartfelt performances, \"La La Land\" can transport you to a world of romance and dreams, offering a sense of escapism and joy.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    {\n",
    "        \"question\": \"Hmmm..I don't want to watch that one. Can you suggest something else?\"\n",
    "    },\n",
    "    {\"configurable\": {\"session_id\": \"1\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "daea2953",
   "metadata": {
    "id": "daea2953"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If you\\'re looking for a lighter movie to watch when feeling sad, I would recommend \"The Devil Wears Prada.\" This comedy-drama film follows the story of a young woman who lands a job at a prestigious fashion magazine, working for a demanding and formidable boss. With its witty humor, stylish setting, and empowering themes, \"The Devil Wears Prada\" can provide entertainment and a dose of laughter to lift your spirits.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    {\"question\": \"How about something more light?\"},\n",
    "    {\"configurable\": {\"session_id\": \"1\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de23a88",
   "metadata": {
    "id": "0de23a88"
   },
   "source": [
    "## Step 7: Get faster responses using Semantic Cache\n",
    "\n",
    "**NOTE:** Semantic cache only caches the input to the LLM. When using it in retrieval chains, remember that documents retrieved can change between runs resulting in cache misses for semantically similar queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d6b6741",
   "metadata": {
    "id": "5d6b6741"
   },
   "outputs": [],
   "source": [
    "from langchain_core.globals import set_llm_cache\n",
    "from langchain_mongodb.cache import MongoDBAtlasSemanticCache\n",
    "\n",
    "set_llm_cache(\n",
    "    MongoDBAtlasSemanticCache(\n",
    "        connection_string=os.environ[\"MONGODB_URI\"],\n",
    "        embedding=embeddings,\n",
    "        collection_name=\"semantic_cache\",\n",
    "        database_name=DB_NAME,\n",
    "        index_name=ATLAS_VECTOR_SEARCH_INDEX_NAME,\n",
    "        wait_until_ready=True,  # Optional, waits until the cache is ready to be used\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb9bc9a2-f239-4445-9369-f1e976bf678d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x115ace8a0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x1171b4da0>, model='text-embedding-ada-002', dimensions=None, deployment='text-embedding-ada-002', openai_api_version=None, openai_api_base=None, openai_api_type=None, openai_proxy=None, embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=None, disallowed_special=None, chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "display(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9825bc7b",
   "metadata": {
    "id": "9825bc7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.8 ms, sys: 18.7 ms, total: 71.5 ms\n",
      "Wall time: 1.32 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A feel-good comedy like \"The Princess Bride\" would be a great choice to watch when feeling sad.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "naive_rag_chain.invoke(\"What is the best movie to watch when sad?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a5e518cf",
   "metadata": {
    "id": "a5e518cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34 ms, sys: 8.27 ms, total: 42.3 ms\n",
      "Wall time: 701 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A feel-good comedy like \"The Princess Bride\" would be a great choice to watch when feeling sad.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "naive_rag_chain.invoke(\"What is the best movie to watch when sad?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d3d3ad3",
   "metadata": {
    "id": "3d3d3ad3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.2 ms, sys: 20.9 ms, total: 72 ms\n",
      "Wall time: 2.91 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A feel-good comedy like \"The Princess Bride\" would be a great choice to watch when feeling sad.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "naive_rag_chain.invoke(\"Which movie do I watch when sad?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e692f36-42d0-472e-bb8a-ee0787a7d225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
