{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dimitarpg13/rag_architectures_and_concepts/blob/main/src/examples/ann/comparisons/approximate_nearest_neighbor_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UazntXs3OR7V"
      },
      "source": [
        "# Approximate Nearest Neighbor (ANN) Algorithms: Implementation and Analysis\n",
        "\n",
        "This notebook provides a comprehensive analysis of Approximate Nearest Neighbor algorithms, comparing:\n",
        "- **Exact KNN** (baseline using brute force)\n",
        "- **Annoy** (Approximate Nearest Neighbors Oh Yeah - Spotify's library)\n",
        "- **FAISS** (Facebook AI Similarity Search)\n",
        "- **KD-Tree** (scikit-learn's tree-based approach)\n",
        "\n",
        "We'll measure:\n",
        "- Recall@K accuracy\n",
        "- Query latency\n",
        "- Index build time\n",
        "- Memory usage patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1-qgYNfOR7W"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install annoy faiss-cpu scikit-learn matplotlib numpy pandas seaborn -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtKg3RMAOR7W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from time import time\n",
        "from typing import List, Tuple, Dict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ANN libraries\n",
        "from annoy import AnnoyIndex\n",
        "import faiss\n",
        "from sklearn.neighbors import NearestNeighbors, KDTree\n",
        "\n",
        "# Set style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"✓ All imports successful\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRmNWub_OR7X"
      },
      "source": [
        "## 1. Data Generation\n",
        "\n",
        "Generate synthetic high-dimensional data to simulate vector embeddings (common in NLP, computer vision, recommendation systems)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wA-nzuxeOR7X"
      },
      "outputs": [],
      "source": [
        "def generate_data(n_samples: int = 10000,\n",
        "                  n_dimensions: int = 128,\n",
        "                  n_queries: int = 100,\n",
        "                  random_state: int = 42) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Generate synthetic high-dimensional data for ANN testing.\n",
        "\n",
        "    Args:\n",
        "        n_samples: Number of vectors in the database\n",
        "        n_dimensions: Dimensionality of each vector\n",
        "        n_queries: Number of query vectors\n",
        "        random_state: Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (database_vectors, query_vectors)\n",
        "    \"\"\"\n",
        "    np.random.seed(random_state)\n",
        "\n",
        "    # Generate database vectors (normalized)\n",
        "    database = np.random.randn(n_samples, n_dimensions).astype('float32')\n",
        "    database = database / np.linalg.norm(database, axis=1, keepdims=True)\n",
        "\n",
        "    # Generate query vectors (normalized)\n",
        "    queries = np.random.randn(n_queries, n_dimensions).astype('float32')\n",
        "    queries = queries / np.linalg.norm(queries, axis=1, keepdims=True)\n",
        "\n",
        "    return database, queries\n",
        "\n",
        "# Generate data\n",
        "N_SAMPLES = 50000\n",
        "N_DIMENSIONS = 128\n",
        "N_QUERIES = 200\n",
        "K = 10  # Number of neighbors to retrieve\n",
        "\n",
        "database_vectors, query_vectors = generate_data(\n",
        "    n_samples=N_SAMPLES,\n",
        "    n_dimensions=N_DIMENSIONS,\n",
        "    n_queries=N_QUERIES\n",
        ")\n",
        "\n",
        "print(f\"Database shape: {database_vectors.shape}\")\n",
        "print(f\"Query shape: {query_vectors.shape}\")\n",
        "print(f\"Memory usage: {(database_vectors.nbytes + query_vectors.nbytes) / 1024**2:.2f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bUuTLCXOR7X"
      },
      "source": [
        "## 2. Exact Nearest Neighbor (Baseline)\n",
        "\n",
        "Brute-force search to establish ground truth for accuracy measurements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICVfnritOR7Y"
      },
      "outputs": [],
      "source": [
        "def exact_knn(database: np.ndarray,\n",
        "              queries: np.ndarray,\n",
        "              k: int) -> Tuple[np.ndarray, float]:\n",
        "    \"\"\"\n",
        "    Exact K-Nearest Neighbors using brute force.\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (indices of k nearest neighbors, query time)\n",
        "    \"\"\"\n",
        "    start_time = time()\n",
        "\n",
        "    # Using sklearn's brute force implementation\n",
        "    nn = NearestNeighbors(n_neighbors=k, algorithm='brute', metric='euclidean')\n",
        "    nn.fit(database)\n",
        "\n",
        "    build_time = time() - start_time\n",
        "\n",
        "    query_start = time()\n",
        "    distances, indices = nn.kneighbors(queries)\n",
        "    query_time = time() - query_start\n",
        "\n",
        "    return indices, build_time, query_time\n",
        "\n",
        "# Compute ground truth\n",
        "print(\"Computing exact KNN (ground truth)...\")\n",
        "ground_truth, exact_build_time, exact_query_time = exact_knn(database_vectors, query_vectors, K)\n",
        "\n",
        "print(f\"Build time: {exact_build_time:.4f}s\")\n",
        "print(f\"Query time: {exact_query_time:.4f}s\")\n",
        "print(f\"Avg time per query: {exact_query_time/N_QUERIES*1000:.2f}ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2cJFuhmOR7Y"
      },
      "source": [
        "## 3. Annoy (Approximate Nearest Neighbors Oh Yeah)\n",
        "\n",
        "Spotify's library using random projection trees. Fast and memory-efficient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pufeTi3SOR7Y"
      },
      "outputs": [],
      "source": [
        "def build_annoy_index(database: np.ndarray,\n",
        "                      n_trees: int = 10,\n",
        "                      metric: str = 'euclidean') -> Tuple[AnnoyIndex, float]:\n",
        "    \"\"\"\n",
        "    Build Annoy index.\n",
        "\n",
        "    Args:\n",
        "        database: Database vectors\n",
        "        n_trees: Number of trees (more trees = better accuracy, slower build)\n",
        "        metric: Distance metric ('euclidean' or 'angular')\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (Annoy index, build time)\n",
        "    \"\"\"\n",
        "    start_time = time()\n",
        "\n",
        "    # Initialize index\n",
        "    index = AnnoyIndex(database.shape[1], metric)\n",
        "\n",
        "    # Add all vectors\n",
        "    for i, vector in enumerate(database):\n",
        "        index.add_item(i, vector)\n",
        "\n",
        "    # Build index\n",
        "    index.build(n_trees)\n",
        "\n",
        "    build_time = time() - start_time\n",
        "    return index, build_time\n",
        "\n",
        "def query_annoy(index: AnnoyIndex,\n",
        "                queries: np.ndarray,\n",
        "                k: int,\n",
        "                search_k: int = -1) -> Tuple[np.ndarray, float]:\n",
        "    \"\"\"\n",
        "    Query Annoy index.\n",
        "\n",
        "    Args:\n",
        "        search_k: Number of nodes to search (-1 = n_trees * k)\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (indices, query time)\n",
        "    \"\"\"\n",
        "    start_time = time()\n",
        "\n",
        "    results = []\n",
        "    for query in queries:\n",
        "        indices = index.get_nns_by_vector(query, k, search_k=search_k)\n",
        "        results.append(indices)\n",
        "\n",
        "    query_time = time() - start_time\n",
        "    return np.array(results), query_time\n",
        "\n",
        "# Test with different numbers of trees\n",
        "print(\"Building Annoy indices...\")\n",
        "annoy_results = {}\n",
        "\n",
        "for n_trees in [5, 10, 20, 50]:\n",
        "    index, build_time = build_annoy_index(database_vectors, n_trees=n_trees)\n",
        "    indices, query_time = query_annoy(index, query_vectors, K)\n",
        "\n",
        "    annoy_results[n_trees] = {\n",
        "        'index': index,\n",
        "        'indices': indices,\n",
        "        'build_time': build_time,\n",
        "        'query_time': query_time\n",
        "    }\n",
        "\n",
        "    print(f\"n_trees={n_trees}: Build={build_time:.4f}s, Query={query_time:.4f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtSogl1gOR7Y"
      },
      "source": [
        "## 4. FAISS (Facebook AI Similarity Search)\n",
        "\n",
        "Industry-standard library with multiple index types. We'll test IVF (Inverted File) and HNSW."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTlX5_JZOR7Y"
      },
      "outputs": [],
      "source": [
        "def build_faiss_flat(database: np.ndarray) -> Tuple[faiss.Index, float]:\n",
        "    \"\"\"\n",
        "    Build FAISS Flat (exact) index for comparison.\n",
        "    \"\"\"\n",
        "    start_time = time()\n",
        "    index = faiss.IndexFlatL2(database.shape[1])\n",
        "    index.add(database)\n",
        "    build_time = time() - start_time\n",
        "    return index, build_time\n",
        "\n",
        "def build_faiss_ivf(database: np.ndarray,\n",
        "                    n_lists: int = 100) -> Tuple[faiss.Index, float]:\n",
        "    \"\"\"\n",
        "    Build FAISS IVF (Inverted File) index.\n",
        "\n",
        "    Args:\n",
        "        n_lists: Number of Voronoi cells (clusters)\n",
        "    \"\"\"\n",
        "    start_time = time()\n",
        "\n",
        "    # Create quantizer and IVF index\n",
        "    quantizer = faiss.IndexFlatL2(database.shape[1])\n",
        "    index = faiss.IndexIVFFlat(quantizer, database.shape[1], n_lists)\n",
        "\n",
        "    # Train on database\n",
        "    index.train(database)\n",
        "    index.add(database)\n",
        "\n",
        "    build_time = time() - start_time\n",
        "    return index, build_time\n",
        "\n",
        "def build_faiss_hnsw(database: np.ndarray,\n",
        "                     M: int = 32) -> Tuple[faiss.Index, float]:\n",
        "    \"\"\"\n",
        "    Build FAISS HNSW (Hierarchical Navigable Small World) index.\n",
        "\n",
        "    Args:\n",
        "        M: Number of connections per node\n",
        "    \"\"\"\n",
        "    start_time = time()\n",
        "    index = faiss.IndexHNSWFlat(database.shape[1], M)\n",
        "    index.add(database)\n",
        "    build_time = time() - start_time\n",
        "    return index, build_time\n",
        "\n",
        "def query_faiss(index: faiss.Index,\n",
        "                queries: np.ndarray,\n",
        "                k: int,\n",
        "                n_probe: int = 1) -> Tuple[np.ndarray, float]:\n",
        "    \"\"\"\n",
        "    Query FAISS index.\n",
        "\n",
        "    Args:\n",
        "        n_probe: Number of clusters to visit (for IVF indices)\n",
        "    \"\"\"\n",
        "    # Set n_probe for IVF indices\n",
        "    if hasattr(index, 'nprobe'):\n",
        "        index.nprobe = n_probe\n",
        "\n",
        "    start_time = time()\n",
        "    distances, indices = index.search(queries, k)\n",
        "    query_time = time() - start_time\n",
        "\n",
        "    return indices, query_time\n",
        "\n",
        "# Build FAISS indices\n",
        "print(\"Building FAISS indices...\")\n",
        "faiss_results = {}\n",
        "\n",
        "# Flat (exact)\n",
        "index_flat, build_time = build_faiss_flat(database_vectors)\n",
        "indices, query_time = query_faiss(index_flat, query_vectors, K)\n",
        "faiss_results['Flat'] = {\n",
        "    'indices': indices,\n",
        "    'build_time': build_time,\n",
        "    'query_time': query_time\n",
        "}\n",
        "print(f\"Flat: Build={build_time:.4f}s, Query={query_time:.4f}s\")\n",
        "\n",
        "# IVF with different n_probe values\n",
        "for n_probe in [1, 5, 10, 20]:\n",
        "    index_ivf, build_time = build_faiss_ivf(database_vectors, n_lists=100)\n",
        "    indices, query_time = query_faiss(index_ivf, query_vectors, K, n_probe=n_probe)\n",
        "    faiss_results[f'IVF_probe{n_probe}'] = {\n",
        "        'indices': indices,\n",
        "        'build_time': build_time,\n",
        "        'query_time': query_time\n",
        "    }\n",
        "    print(f\"IVF (n_probe={n_probe}): Build={build_time:.4f}s, Query={query_time:.4f}s\")\n",
        "\n",
        "# HNSW\n",
        "index_hnsw, build_time = build_faiss_hnsw(database_vectors, M=32)\n",
        "indices, query_time = query_faiss(index_hnsw, query_vectors, K)\n",
        "faiss_results['HNSW'] = {\n",
        "    'indices': indices,\n",
        "    'build_time': build_time,\n",
        "    'query_time': query_time\n",
        "}\n",
        "print(f\"HNSW: Build={build_time:.4f}s, Query={query_time:.4f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDpgv0asOR7Z"
      },
      "source": [
        "## 5. KD-Tree (sklearn)\n",
        "\n",
        "Tree-based approach from scikit-learn. Works well in lower dimensions but degrades in high dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EA9s5hxMOR7Z"
      },
      "outputs": [],
      "source": [
        "def build_kdtree(database: np.ndarray,\n",
        "                 leaf_size: int = 30) -> Tuple[KDTree, float]:\n",
        "    \"\"\"\n",
        "    Build KD-Tree index.\n",
        "    \"\"\"\n",
        "    start_time = time()\n",
        "    tree = KDTree(database, leaf_size=leaf_size)\n",
        "    build_time = time() - start_time\n",
        "    return tree, build_time\n",
        "\n",
        "def query_kdtree(tree: KDTree,\n",
        "                 queries: np.ndarray,\n",
        "                 k: int) -> Tuple[np.ndarray, float]:\n",
        "    \"\"\"\n",
        "    Query KD-Tree.\n",
        "    \"\"\"\n",
        "    start_time = time()\n",
        "    distances, indices = tree.query(queries, k=k)\n",
        "    query_time = time() - start_time\n",
        "    return indices, query_time\n",
        "\n",
        "# Build KD-Tree\n",
        "print(\"Building KD-Tree...\")\n",
        "kdtree, build_time = build_kdtree(database_vectors)\n",
        "kdtree_indices, query_time = query_kdtree(kdtree, query_vectors, K)\n",
        "\n",
        "print(f\"Build time: {build_time:.4f}s\")\n",
        "print(f\"Query time: {query_time:.4f}s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOqkauldOR7Z"
      },
      "source": [
        "## 6. Accuracy Metrics\n",
        "\n",
        "Calculate Recall@K: the fraction of true nearest neighbors found by the approximate method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2820n29cOR7Z"
      },
      "outputs": [],
      "source": [
        "def calculate_recall_at_k(ground_truth: np.ndarray,\n",
        "                          predictions: np.ndarray) -> float:\n",
        "    \"\"\"\n",
        "    Calculate Recall@K.\n",
        "\n",
        "    Args:\n",
        "        ground_truth: True nearest neighbors [n_queries, k]\n",
        "        predictions: Predicted nearest neighbors [n_queries, k]\n",
        "\n",
        "    Returns:\n",
        "        Average recall across all queries\n",
        "    \"\"\"\n",
        "    recalls = []\n",
        "\n",
        "    for true_neighbors, pred_neighbors in zip(ground_truth, predictions):\n",
        "        # Count how many predicted neighbors are in the true set\n",
        "        intersection = len(set(true_neighbors) & set(pred_neighbors))\n",
        "        recall = intersection / len(true_neighbors)\n",
        "        recalls.append(recall)\n",
        "\n",
        "    return np.mean(recalls)\n",
        "\n",
        "# Calculate recall for all methods\n",
        "results_df = []\n",
        "\n",
        "# Exact KNN (should be 1.0)\n",
        "results_df.append({\n",
        "    'Method': 'Exact KNN',\n",
        "    'Recall@K': 1.0,\n",
        "    'Build Time (s)': exact_build_time,\n",
        "    'Query Time (s)': exact_query_time,\n",
        "    'Avg Query (ms)': exact_query_time / N_QUERIES * 1000\n",
        "})\n",
        "\n",
        "# Annoy\n",
        "for n_trees, data in annoy_results.items():\n",
        "    recall = calculate_recall_at_k(ground_truth, data['indices'])\n",
        "    results_df.append({\n",
        "        'Method': f'Annoy (trees={n_trees})',\n",
        "        'Recall@K': recall,\n",
        "        'Build Time (s)': data['build_time'],\n",
        "        'Query Time (s)': data['query_time'],\n",
        "        'Avg Query (ms)': data['query_time'] / N_QUERIES * 1000\n",
        "    })\n",
        "\n",
        "# FAISS\n",
        "for name, data in faiss_results.items():\n",
        "    recall = calculate_recall_at_k(ground_truth, data['indices'])\n",
        "    results_df.append({\n",
        "        'Method': f'FAISS {name}',\n",
        "        'Recall@K': recall,\n",
        "        'Build Time (s)': data['build_time'],\n",
        "        'Query Time (s)': data['query_time'],\n",
        "        'Avg Query (ms)': data['query_time'] / N_QUERIES * 1000\n",
        "    })\n",
        "\n",
        "# KD-Tree\n",
        "kdtree_recall = calculate_recall_at_k(ground_truth, kdtree_indices)\n",
        "results_df.append({\n",
        "    'Method': 'KD-Tree',\n",
        "    'Recall@K': kdtree_recall,\n",
        "    'Build Time (s)': build_time,\n",
        "    'Query Time (s)': query_time,\n",
        "    'Avg Query (ms)': query_time / N_QUERIES * 1000\n",
        "})\n",
        "\n",
        "results_df = pd.DataFrame(results_df)\n",
        "results_df = results_df.sort_values('Recall@K', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PERFORMANCE COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "print(results_df.to_string(index=False))\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcD_F7jwOR7a"
      },
      "source": [
        "## 7. Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pM8HZ0FnOR7a"
      },
      "outputs": [],
      "source": [
        "# Create comprehensive visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# 1. Recall vs Query Time (Speed-Accuracy Tradeoff)\n",
        "ax1 = axes[0, 0]\n",
        "for _, row in results_df.iterrows():\n",
        "    color = 'red' if 'Exact' in row['Method'] else 'blue' if 'Annoy' in row['Method'] else 'green' if 'FAISS' in row['Method'] else 'orange'\n",
        "    marker = 'o' if 'Exact' in row['Method'] else 's' if 'Annoy' in row['Method'] else '^' if 'FAISS' in row['Method'] else 'd'\n",
        "    ax1.scatter(row['Avg Query (ms)'], row['Recall@K'],\n",
        "               s=150, alpha=0.7, color=color, marker=marker,\n",
        "               label=row['Method'])\n",
        "\n",
        "ax1.set_xlabel('Average Query Time (ms)', fontsize=12, fontweight='bold')\n",
        "ax1.set_ylabel('Recall@K', fontsize=12, fontweight='bold')\n",
        "ax1.set_title('Speed-Accuracy Tradeoff', fontsize=14, fontweight='bold')\n",
        "ax1.set_xscale('log')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
        "\n",
        "# 2. Build Time Comparison\n",
        "ax2 = axes[0, 1]\n",
        "methods = results_df['Method'].str.replace('FAISS ', '').str.replace('Annoy ', 'A-')\n",
        "colors = ['red' if 'Exact' in m else 'blue' if 'A-' in m else 'green' if any(x in m for x in ['Flat', 'IVF', 'HNSW']) else 'orange'\n",
        "          for m in results_df['Method']]\n",
        "bars = ax2.barh(range(len(methods)), results_df['Build Time (s)'], color=colors, alpha=0.7)\n",
        "ax2.set_yticks(range(len(methods)))\n",
        "ax2.set_yticklabels(methods, fontsize=9)\n",
        "ax2.set_xlabel('Build Time (seconds)', fontsize=12, fontweight='bold')\n",
        "ax2.set_title('Index Build Time Comparison', fontsize=14, fontweight='bold')\n",
        "ax2.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# Add value labels\n",
        "for i, (bar, val) in enumerate(zip(bars, results_df['Build Time (s)'])):\n",
        "    ax2.text(val, bar.get_y() + bar.get_height()/2, f'{val:.3f}s',\n",
        "            va='center', ha='left', fontsize=8, fontweight='bold')\n",
        "\n",
        "# 3. Query Time Comparison\n",
        "ax3 = axes[1, 0]\n",
        "bars = ax3.barh(range(len(methods)), results_df['Avg Query (ms)'], color=colors, alpha=0.7)\n",
        "ax3.set_yticks(range(len(methods)))\n",
        "ax3.set_yticklabels(methods, fontsize=9)\n",
        "ax3.set_xlabel('Average Query Time (ms)', fontsize=12, fontweight='bold')\n",
        "ax3.set_title('Query Performance Comparison', fontsize=14, fontweight='bold')\n",
        "ax3.set_xscale('log')\n",
        "ax3.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# Add value labels\n",
        "for i, (bar, val) in enumerate(zip(bars, results_df['Avg Query (ms)'])):\n",
        "    ax3.text(val * 1.1, bar.get_y() + bar.get_height()/2, f'{val:.2f}ms',\n",
        "            va='center', ha='left', fontsize=8, fontweight='bold')\n",
        "\n",
        "# 4. Recall Comparison\n",
        "ax4 = axes[1, 1]\n",
        "bars = ax4.barh(range(len(methods)), results_df['Recall@K'], color=colors, alpha=0.7)\n",
        "ax4.set_yticks(range(len(methods)))\n",
        "ax4.set_yticklabels(methods, fontsize=9)\n",
        "ax4.set_xlabel('Recall@K', fontsize=12, fontweight='bold')\n",
        "ax4.set_title('Accuracy Comparison (Recall@10)', fontsize=14, fontweight='bold')\n",
        "ax4.set_xlim([0, 1.05])\n",
        "ax4.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# Add value labels\n",
        "for i, (bar, val) in enumerate(zip(bars, results_df['Recall@K'])):\n",
        "    ax4.text(val, bar.get_y() + bar.get_height()/2, f'{val:.3f}',\n",
        "            va='center', ha='right' if val > 0.5 else 'left',\n",
        "            fontsize=8, fontweight='bold',\n",
        "            color='white' if val > 0.5 else 'black')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('/home/claude/ann_comparison.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n✓ Visualizations saved to 'ann_comparison.png'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqQ36ecgOR7a"
      },
      "source": [
        "## 8. Detailed Analysis: Pareto Frontier\n",
        "\n",
        "Identify methods on the Pareto frontier (best speed-accuracy tradeoffs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUL6P0zMOR7a"
      },
      "outputs": [],
      "source": [
        "def find_pareto_frontier(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Find Pareto-optimal points (maximize recall, minimize query time).\n",
        "    \"\"\"\n",
        "    pareto_points = []\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        is_pareto = True\n",
        "        for j, other_row in df.iterrows():\n",
        "            if i != j:\n",
        "                # Other point dominates if it has better or equal recall AND better query time\n",
        "                if (other_row['Recall@K'] >= row['Recall@K'] and\n",
        "                    other_row['Avg Query (ms)'] < row['Avg Query (ms)']):\n",
        "                    is_pareto = False\n",
        "                    break\n",
        "\n",
        "        if is_pareto:\n",
        "            pareto_points.append(row)\n",
        "\n",
        "    return pd.DataFrame(pareto_points)\n",
        "\n",
        "# Find and plot Pareto frontier\n",
        "pareto_df = find_pareto_frontier(results_df)\n",
        "pareto_df = pareto_df.sort_values('Avg Query (ms)')\n",
        "\n",
        "plt.figure(figsize=(12, 7))\n",
        "\n",
        "# Plot all points\n",
        "for _, row in results_df.iterrows():\n",
        "    is_pareto = row['Method'] in pareto_df['Method'].values\n",
        "    color = 'red' if 'Exact' in row['Method'] else 'blue' if 'Annoy' in row['Method'] else 'green' if 'FAISS' in row['Method'] else 'orange'\n",
        "    marker = 'o' if 'Exact' in row['Method'] else 's' if 'Annoy' in row['Method'] else '^' if 'FAISS' in row['Method'] else 'd'\n",
        "\n",
        "    plt.scatter(row['Avg Query (ms)'], row['Recall@K'],\n",
        "               s=300 if is_pareto else 150,\n",
        "               alpha=1.0 if is_pareto else 0.4,\n",
        "               color=color,\n",
        "               marker=marker,\n",
        "               edgecolors='black' if is_pareto else 'none',\n",
        "               linewidths=2 if is_pareto else 0,\n",
        "               label=row['Method'] if is_pareto else '',\n",
        "               zorder=10 if is_pareto else 5)\n",
        "\n",
        "    # Add labels for Pareto points\n",
        "    if is_pareto:\n",
        "        plt.annotate(row['Method'],\n",
        "                    (row['Avg Query (ms)'], row['Recall@K']),\n",
        "                    xytext=(10, 10), textcoords='offset points',\n",
        "                    fontsize=9, fontweight='bold',\n",
        "                    bbox=dict(boxstyle='round,pad=0.5', facecolor=color, alpha=0.3))\n",
        "\n",
        "# Draw Pareto frontier line\n",
        "plt.plot(pareto_df['Avg Query (ms)'], pareto_df['Recall@K'],\n",
        "         'k--', linewidth=2, alpha=0.5, label='Pareto Frontier', zorder=8)\n",
        "\n",
        "plt.xlabel('Average Query Time (ms)', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Recall@K', fontsize=14, fontweight='bold')\n",
        "plt.title('Pareto Frontier: Speed-Accuracy Tradeoff\\n(Larger points with black borders are Pareto-optimal)',\n",
        "         fontsize=15, fontweight='bold')\n",
        "plt.xscale('log')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend(fontsize=10, loc='lower left')\n",
        "plt.tight_layout()\n",
        "plt.savefig('/home/claude/pareto_frontier.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nPareto-Optimal Methods:\")\n",
        "print(pareto_df[['Method', 'Recall@K', 'Avg Query (ms)', 'Build Time (s)']].to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltWnlgjaOR7a"
      },
      "source": [
        "## 9. Distance Distribution Analysis\n",
        "\n",
        "Visualize how approximate methods compare to exact search in terms of actual distances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6huYXqGOR7b"
      },
      "outputs": [],
      "source": [
        "def compute_distances(database: np.ndarray,\n",
        "                     queries: np.ndarray,\n",
        "                     indices: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Compute actual L2 distances for retrieved neighbors.\n",
        "    \"\"\"\n",
        "    distances = []\n",
        "    for query_idx, neighbor_indices in enumerate(indices):\n",
        "        query = queries[query_idx]\n",
        "        neighbors = database[neighbor_indices]\n",
        "        dists = np.linalg.norm(neighbors - query, axis=1)\n",
        "        distances.append(dists)\n",
        "    return np.array(distances)\n",
        "\n",
        "# Compute distances for select methods\n",
        "exact_distances = compute_distances(database_vectors, query_vectors, ground_truth)\n",
        "annoy_10_distances = compute_distances(database_vectors, query_vectors, annoy_results[10]['indices'])\n",
        "hnsw_distances = compute_distances(database_vectors, query_vectors, faiss_results['HNSW']['indices'])\n",
        "\n",
        "# Plot distance distributions\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "methods_to_plot = [\n",
        "    ('Exact KNN', exact_distances, 'red'),\n",
        "    ('Annoy (10 trees)', annoy_10_distances, 'blue'),\n",
        "    ('FAISS HNSW', hnsw_distances, 'green')\n",
        "]\n",
        "\n",
        "for ax, (method, distances, color) in zip(axes, methods_to_plot):\n",
        "    # Flatten all distances\n",
        "    flat_distances = distances.flatten()\n",
        "\n",
        "    ax.hist(flat_distances, bins=50, alpha=0.7, color=color, edgecolor='black')\n",
        "    ax.axvline(flat_distances.mean(), color='darkred', linestyle='--', linewidth=2,\n",
        "              label=f'Mean: {flat_distances.mean():.4f}')\n",
        "    ax.set_xlabel('L2 Distance', fontsize=12, fontweight='bold')\n",
        "    ax.set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
        "    ax.set_title(f'{method}\\nDistance Distribution', fontsize=13, fontweight='bold')\n",
        "    ax.legend(fontsize=10)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('/home/claude/distance_distributions.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rtl59wrOR7b"
      },
      "source": [
        "## 10. Summary and Recommendations\n",
        "\n",
        "### Key Findings:\n",
        "\n",
        "1. **Speed vs Accuracy Tradeoff**: Approximate methods can achieve 10-100x speedup with 90-99% recall\n",
        "\n",
        "2. **Best Overall**: FAISS HNSW typically offers the best balance (high recall, fast queries)\n",
        "\n",
        "3. **Memory Constrained**: Annoy is excellent for memory-limited scenarios\n",
        "\n",
        "4. **High Dimensions**: KD-Tree degrades significantly in high dimensions (curse of dimensionality)\n",
        "\n",
        "### Production Recommendations:\n",
        "\n",
        "- **<100k vectors**: FAISS HNSW or Annoy\n",
        "- **100k-10M vectors**: FAISS IVF or HNSW\n",
        "- **>10M vectors**: FAISS with GPU support or distributed solutions\n",
        "- **Real-time requirements**: HNSW (best query latency)\n",
        "- **Batch processing**: IVF (good throughput, acceptable latency)\n",
        "\n",
        "### Tuning Guidelines:\n",
        "\n",
        "- **Annoy**: Increase `n_trees` for better recall (linear build time increase)\n",
        "- **FAISS IVF**: Increase `n_probe` for better recall (linear query time increase)\n",
        "- **FAISS HNSW**: Increase `M` for better recall (higher memory usage)\n",
        "\n",
        "### Further Reading:\n",
        "\n",
        "- [FAISS Documentation](https://github.com/facebookresearch/faiss/wiki)\n",
        "- [Annoy GitHub](https://github.com/spotify/annoy)\n",
        "- [ANN Benchmarks](http://ann-benchmarks.com/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GFR3U9hOR7b"
      },
      "outputs": [],
      "source": [
        "# Export results to CSV\n",
        "results_df.to_csv('/home/claude/ann_benchmark_results.csv', index=False)\n",
        "print(\"\\n✓ Results exported to 'ann_benchmark_results.csv'\")\n",
        "print(\"\\n✓ Notebook execution complete!\")\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FINAL SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Database size: {N_SAMPLES:,} vectors × {N_DIMENSIONS} dimensions\")\n",
        "print(f\"Number of queries: {N_QUERIES}\")\n",
        "print(f\"K (neighbors to retrieve): {K}\")\n",
        "print(f\"\\nTop 3 methods by recall:\")\n",
        "print(results_df.nlargest(3, 'Recall@K')[['Method', 'Recall@K', 'Avg Query (ms)']].to_string(index=False))\n",
        "print(f\"\\nTop 3 methods by speed:\")\n",
        "print(results_df.nsmallest(3, 'Avg Query (ms)')[['Method', 'Recall@K', 'Avg Query (ms)']].to_string(index=False))\n",
        "print(\"=\"*80)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}