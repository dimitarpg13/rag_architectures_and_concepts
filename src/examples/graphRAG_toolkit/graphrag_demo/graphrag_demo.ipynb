{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üï∏Ô∏è GraphRAG Toolkit Demo\n",
        "\n",
        "This notebook demonstrates how to use Microsoft's **GraphRAG** (Graph-based Retrieval-Augmented Generation) toolkit. GraphRAG enhances traditional RAG by building a knowledge graph from your documents, enabling more nuanced and comprehensive answers to complex queries.\n",
        "\n",
        "## What is GraphRAG?\n",
        "\n",
        "GraphRAG is an advanced RAG approach that:\n",
        "- **Extracts entities and relationships** from documents to build a knowledge graph\n",
        "- **Creates community summaries** for hierarchical understanding\n",
        "- **Supports two query modes**:\n",
        "  - **Local Search**: Best for specific questions about particular entities\n",
        "  - **Global Search**: Best for broad questions requiring synthesis across the corpus\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ 1. Installation\n",
        "\n",
        "First, let's install the GraphRAG toolkit and its dependencies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install GraphRAG toolkit\n",
        "!pip install graphrag --quiet\n",
        "\n",
        "# Additional dependencies\n",
        "!pip install python-dotenv pyyaml --quiet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß 2. Environment Setup\n",
        "\n",
        "GraphRAG requires an LLM (Language Model) and an embedding model. We'll configure these using environment variables.\n",
        "\n",
        "**Supported LLM providers:**\n",
        "- OpenAI\n",
        "- Azure OpenAI\n",
        "- Other OpenAI-compatible APIs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file if it exists\n",
        "load_dotenv()\n",
        "\n",
        "# Set your OpenAI API key (uncomment and set your key)\n",
        "# os.environ[\"GRAPHRAG_API_KEY\"] = \"your-openai-api-key-here\"\n",
        "\n",
        "# Alternatively, you can set it directly:\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key-here\"\n",
        "\n",
        "# Verify the API key is set\n",
        "api_key = os.environ.get(\"GRAPHRAG_API_KEY\") or os.environ.get(\"OPENAI_API_KEY\")\n",
        "if api_key:\n",
        "    print(\"‚úÖ API key is configured\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Warning: No API key found. Please set GRAPHRAG_API_KEY or OPENAI_API_KEY\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìÅ 3. Project Structure Setup\n",
        "\n",
        "GraphRAG expects a specific project structure. Let's create it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define project directories\n",
        "PROJECT_DIR = Path.cwd()\n",
        "INPUT_DIR = PROJECT_DIR / \"input\"\n",
        "OUTPUT_DIR = PROJECT_DIR / \"output\"\n",
        "\n",
        "# Create directories\n",
        "INPUT_DIR.mkdir(exist_ok=True)\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"üìÇ Project directory: {PROJECT_DIR}\")\n",
        "print(f\"üìÇ Input directory: {INPUT_DIR}\")\n",
        "print(f\"üìÇ Output directory: {OUTPUT_DIR}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìÑ 4. Sample Data Preparation\n",
        "\n",
        "For this demo, we'll create a sample text document. You can replace this with your own documents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample text about a fictional tech company for demonstration\n",
        "sample_text = \"\"\"\n",
        "# TechCorp Innovation Report 2025\n",
        "\n",
        "## Company Overview\n",
        "\n",
        "TechCorp is a leading technology company founded in 2015 by Sarah Chen and Michael Rodriguez in San Francisco. \n",
        "The company specializes in artificial intelligence solutions for enterprise customers. With over 5,000 employees \n",
        "across 20 offices worldwide, TechCorp has become a major player in the AI industry.\n",
        "\n",
        "## Leadership Team\n",
        "\n",
        "Sarah Chen serves as the CEO and has led the company through multiple successful funding rounds. She previously \n",
        "worked at Google and Stanford AI Lab. Michael Rodriguez, the CTO, oversees all technical operations and R&D. \n",
        "He holds a PhD in Machine Learning from MIT.\n",
        "\n",
        "The CFO, Jennifer Park, joined in 2019 from Goldman Sachs. She has been instrumental in the company's financial \n",
        "growth and successful IPO in 2023. David Thompson leads the Sales division and has expanded the customer base \n",
        "to include Fortune 500 companies like Amazon, Microsoft, and Walmart.\n",
        "\n",
        "## Products and Services\n",
        "\n",
        "TechCorp's flagship product, \"AIAssist Pro\", is an enterprise AI assistant that helps companies automate \n",
        "customer service operations. It uses advanced natural language processing and has been deployed by over \n",
        "200 enterprise customers.\n",
        "\n",
        "\"DataSense Analytics\" is the company's second major product, offering predictive analytics for supply chain \n",
        "optimization. Major clients include Walmart and Target, who have reported 30% efficiency improvements.\n",
        "\n",
        "The newest product, \"SecureAI\", launched in 2024, focuses on AI-powered cybersecurity. It has already \n",
        "attracted partnerships with three major banks: JPMorgan Chase, Bank of America, and Wells Fargo.\n",
        "\n",
        "## Research and Development\n",
        "\n",
        "TechCorp's R&D division, led by Dr. Emily Watson, has published over 50 papers in top AI conferences. \n",
        "The team recently made a breakthrough in efficient transformer architectures, reducing compute costs by 40%.\n",
        "\n",
        "The company collaborates with Stanford University, MIT, and Carnegie Mellon on various research projects. \n",
        "Dr. Watson's team includes researchers from DeepMind, OpenAI, and Google Brain.\n",
        "\n",
        "## Financial Performance\n",
        "\n",
        "In 2024, TechCorp reported revenue of $2.5 billion, a 45% increase from the previous year. The company's \n",
        "market cap reached $50 billion after the successful IPO. Major investors include Sequoia Capital, \n",
        "Andreessen Horowitz, and SoftBank Vision Fund.\n",
        "\n",
        "## Future Plans\n",
        "\n",
        "TechCorp plans to expand into the healthcare AI market in 2025, with partnerships already in place with \n",
        "Mayo Clinic and Cleveland Clinic. The company is also developing autonomous systems for logistics, \n",
        "working with FedEx and UPS on pilot programs.\n",
        "\n",
        "Sarah Chen announced plans to open new R&D centers in London, Singapore, and Tel Aviv to attract \n",
        "global talent and serve international customers better.\n",
        "\"\"\"\n",
        "\n",
        "# Save the sample text to the input directory\n",
        "input_file = INPUT_DIR / \"techcorp_report.txt\"\n",
        "input_file.write_text(sample_text)\n",
        "\n",
        "print(f\"‚úÖ Sample document saved to: {input_file}\")\n",
        "print(f\"üìù Document length: {len(sample_text)} characters\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚öôÔ∏è 5. Configuration\n",
        "\n",
        "GraphRAG uses a `settings.yaml` file for configuration. Let's create one with sensible defaults.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "# GraphRAG configuration\n",
        "settings = {\n",
        "    \"llm\": {\n",
        "        \"api_key\": \"${GRAPHRAG_API_KEY}\",  # Uses environment variable\n",
        "        \"type\": \"openai_chat\",\n",
        "        \"model\": \"gpt-4o-mini\",  # Cost-effective model for demo\n",
        "        \"model_supports_json\": True,\n",
        "        \"max_tokens\": 4000,\n",
        "        \"temperature\": 0,\n",
        "    },\n",
        "    \"embeddings\": {\n",
        "        \"llm\": {\n",
        "            \"api_key\": \"${GRAPHRAG_API_KEY}\",\n",
        "            \"type\": \"openai_embedding\",\n",
        "            \"model\": \"text-embedding-3-small\",\n",
        "        }\n",
        "    },\n",
        "    \"input\": {\n",
        "        \"type\": \"file\",\n",
        "        \"file_type\": \"text\",\n",
        "        \"base_dir\": \"input\",\n",
        "        \"file_encoding\": \"utf-8\",\n",
        "        \"file_pattern\": \".*\\\\.txt$\"\n",
        "    },\n",
        "    \"storage\": {\n",
        "        \"type\": \"file\",\n",
        "        \"base_dir\": \"output\"\n",
        "    },\n",
        "    \"cache\": {\n",
        "        \"type\": \"file\",\n",
        "        \"base_dir\": \"cache\"\n",
        "    },\n",
        "    \"reporting\": {\n",
        "        \"type\": \"file\",\n",
        "        \"base_dir\": \"logs\"\n",
        "    },\n",
        "    \"chunks\": {\n",
        "        \"size\": 1200,\n",
        "        \"overlap\": 100\n",
        "    },\n",
        "    \"entity_extraction\": {\n",
        "        \"max_gleanings\": 1\n",
        "    },\n",
        "    \"claim_extraction\": {\n",
        "        \"enabled\": True\n",
        "    },\n",
        "    \"community_reports\": {\n",
        "        \"max_length\": 2000\n",
        "    },\n",
        "    \"cluster_graph\": {\n",
        "        \"max_cluster_size\": 10\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save settings to YAML file\n",
        "settings_file = PROJECT_DIR / \"settings.yaml\"\n",
        "with open(settings_file, 'w') as f:\n",
        "    yaml.dump(settings, f, default_flow_style=False, sort_keys=False)\n",
        "\n",
        "print(f\"‚úÖ Configuration saved to: {settings_file}\")\n",
        "print(\"\\nüìã Settings preview:\")\n",
        "print(yaml.dump(settings, default_flow_style=False, sort_keys=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç 6. Initialize GraphRAG\n",
        "\n",
        "Alternatively, you can use the CLI to initialize a project with `graphrag init --root .`\n",
        "\n",
        "Let's verify the GraphRAG library is installed correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if we can import graphrag\n",
        "try:\n",
        "    import graphrag\n",
        "    print(f\"‚úÖ GraphRAG version: {graphrag.__version__ if hasattr(graphrag, '__version__') else 'installed'}\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå GraphRAG not installed: {e}\")\n",
        "    print(\"Run: pip install graphrag\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèóÔ∏è 7. Indexing Documents\n",
        "\n",
        "The indexing process:\n",
        "1. **Chunks** documents into smaller pieces\n",
        "2. **Extracts** entities and relationships using the LLM\n",
        "3. **Builds** a knowledge graph\n",
        "4. **Creates** community summaries using the Leiden algorithm\n",
        "5. **Generates** embeddings for semantic search\n",
        "\n",
        "‚ö†Ô∏è **Note**: Indexing uses LLM API calls and may take several minutes and incur costs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Method 1: Using CLI (recommended for larger documents)\n",
        "# Run this in a terminal: graphrag index --root .\n",
        "\n",
        "# Method 2: Using Python API\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def run_graphrag_index():\n",
        "    \"\"\"Run GraphRAG indexing process.\"\"\"\n",
        "    print(\"üöÄ Starting GraphRAG indexing...\")\n",
        "    print(\"This may take several minutes depending on document size.\\n\")\n",
        "    \n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            [sys.executable, \"-m\", \"graphrag\", \"index\", \"--root\", str(PROJECT_DIR)],\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            cwd=str(PROJECT_DIR)\n",
        "        )\n",
        "        \n",
        "        if result.returncode == 0:\n",
        "            print(\"‚úÖ Indexing completed successfully!\")\n",
        "            print(result.stdout)\n",
        "        else:\n",
        "            print(\"‚ùå Indexing failed:\")\n",
        "            print(result.stderr)\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error running indexing: {e}\")\n",
        "\n",
        "# Uncomment the line below to run indexing\n",
        "# run_graphrag_index()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Alternative: Run indexing via command line\n",
        "\n",
        "You can also run the indexing from the command line:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to run indexing via shell\n",
        "# !graphrag index --root .\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîé 8. Querying the Knowledge Graph\n",
        "\n",
        "GraphRAG supports two types of queries:\n",
        "\n",
        "### Local Search\n",
        "- Best for **specific questions** about particular entities or facts\n",
        "- Uses entity embeddings and local graph context\n",
        "- Example: \"Who is the CEO of TechCorp?\"\n",
        "\n",
        "### Global Search  \n",
        "- Best for **broad questions** requiring synthesis across the entire corpus\n",
        "- Uses community summaries for high-level understanding\n",
        "- Example: \"What are the main business areas of TechCorp?\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_graphrag_query(query: str, method: str = \"local\"):\n",
        "    \"\"\"\n",
        "    Run a GraphRAG query.\n",
        "    \n",
        "    Args:\n",
        "        query: The question to ask\n",
        "        method: 'local' or 'global' search method\n",
        "    \"\"\"\n",
        "    print(f\"üîç Query: {query}\")\n",
        "    print(f\"üìä Method: {method.upper()} search\\n\")\n",
        "    \n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            [\n",
        "                sys.executable, \"-m\", \"graphrag\", \"query\",\n",
        "                \"--root\", str(PROJECT_DIR),\n",
        "                \"--method\", method,\n",
        "                \"--query\", query\n",
        "            ],\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            cwd=str(PROJECT_DIR)\n",
        "        )\n",
        "        \n",
        "        if result.returncode == 0:\n",
        "            print(\"üìù Response:\")\n",
        "            print(\"-\" * 50)\n",
        "            print(result.stdout)\n",
        "        else:\n",
        "            print(\"‚ùå Query failed:\")\n",
        "            print(result.stderr)\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error running query: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example Queries\n",
        "\n",
        "Try these example queries after indexing is complete:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Local Search - specific entity questions\n",
        "# Uncomment after indexing is complete\n",
        "\n",
        "# run_graphrag_query(\"Who is Sarah Chen and what is her role at TechCorp?\", method=\"local\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# run_graphrag_query(\"What products does TechCorp offer?\", method=\"local\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Global Search - broad synthesis questions\n",
        "# run_graphrag_query(\"What are the main themes and topics discussed in the document?\", method=\"global\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# run_graphrag_query(\"Summarize TechCorp's business strategy and future plans.\", method=\"global\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä 9. Exploring the Knowledge Graph\n",
        "\n",
        "After indexing, GraphRAG creates several output files that you can explore:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def explore_graphrag_outputs():\n",
        "    \"\"\"Explore the GraphRAG output files.\"\"\"\n",
        "    output_artifacts = OUTPUT_DIR / \"artifacts\"\n",
        "    \n",
        "    if not output_artifacts.exists():\n",
        "        print(\"‚ö†Ô∏è  Output directory not found. Run indexing first.\")\n",
        "        return\n",
        "    \n",
        "    # List available output files\n",
        "    print(\"üìÅ Available output files:\")\n",
        "    for file in output_artifacts.glob(\"*.parquet\"):\n",
        "        print(f\"  - {file.name}\")\n",
        "    \n",
        "    # Try to load and display entities\n",
        "    entities_file = output_artifacts / \"create_final_entities.parquet\"\n",
        "    if entities_file.exists():\n",
        "        print(\"\\nüè∑Ô∏è  Extracted Entities:\")\n",
        "        entities_df = pd.read_parquet(entities_file)\n",
        "        print(entities_df[['name', 'type', 'description']].head(10))\n",
        "    \n",
        "    # Try to load and display relationships\n",
        "    rels_file = output_artifacts / \"create_final_relationships.parquet\"\n",
        "    if rels_file.exists():\n",
        "        print(\"\\nüîó Extracted Relationships:\")\n",
        "        rels_df = pd.read_parquet(rels_file)\n",
        "        print(rels_df[['source', 'target', 'description']].head(10))\n",
        "\n",
        "# Uncomment after indexing\n",
        "# explore_graphrag_outputs()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé® 10. Visualizing the Knowledge Graph\n",
        "\n",
        "Let's create a visualization of the extracted knowledge graph.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install visualization libraries\n",
        "!pip install networkx matplotlib --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_knowledge_graph():\n",
        "    \"\"\"Create a visualization of the knowledge graph.\"\"\"\n",
        "    output_artifacts = OUTPUT_DIR / \"artifacts\"\n",
        "    \n",
        "    entities_file = output_artifacts / \"create_final_entities.parquet\"\n",
        "    rels_file = output_artifacts / \"create_final_relationships.parquet\"\n",
        "    \n",
        "    if not entities_file.exists() or not rels_file.exists():\n",
        "        print(\"‚ö†Ô∏è  Output files not found. Run indexing first.\")\n",
        "        return\n",
        "    \n",
        "    # Load data\n",
        "    entities_df = pd.read_parquet(entities_file)\n",
        "    rels_df = pd.read_parquet(rels_file)\n",
        "    \n",
        "    # Create graph\n",
        "    G = nx.Graph()\n",
        "    \n",
        "    # Add nodes\n",
        "    for _, row in entities_df.iterrows():\n",
        "        G.add_node(row['name'], type=row.get('type', 'UNKNOWN'))\n",
        "    \n",
        "    # Add edges\n",
        "    for _, row in rels_df.iterrows():\n",
        "        G.add_edge(row['source'], row['target'])\n",
        "    \n",
        "    # Create visualization\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    \n",
        "    # Color nodes by type\n",
        "    node_types = nx.get_node_attributes(G, 'type')\n",
        "    unique_types = list(set(node_types.values()))\n",
        "    color_map = plt.cm.get_cmap('tab10')\n",
        "    colors = [color_map(unique_types.index(node_types.get(node, 'UNKNOWN')) % 10) for node in G.nodes()]\n",
        "    \n",
        "    # Layout\n",
        "    pos = nx.spring_layout(G, k=2, iterations=50)\n",
        "    \n",
        "    # Draw\n",
        "    nx.draw(G, pos, \n",
        "            node_color=colors,\n",
        "            node_size=1000,\n",
        "            font_size=8,\n",
        "            font_weight='bold',\n",
        "            with_labels=True,\n",
        "            edge_color='gray',\n",
        "            alpha=0.7)\n",
        "    \n",
        "    plt.title(\"GraphRAG Knowledge Graph\", fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # Add legend\n",
        "    legend_elements = [plt.Line2D([0], [0], marker='o', color='w', \n",
        "                                   markerfacecolor=color_map(i % 10), \n",
        "                                   markersize=10, label=t) \n",
        "                       for i, t in enumerate(unique_types)]\n",
        "    plt.legend(handles=legend_elements, loc='upper left', title='Entity Types')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(PROJECT_DIR / 'knowledge_graph.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"\\nüìä Graph Statistics:\")\n",
        "    print(f\"   Nodes: {G.number_of_nodes()}\")\n",
        "    print(f\"   Edges: {G.number_of_edges()}\")\n",
        "    print(f\"   Entity Types: {unique_types}\")\n",
        "\n",
        "# Uncomment after indexing\n",
        "# visualize_knowledge_graph()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Cleanup\n",
        "\n",
        "Optional: Remove generated files to start fresh.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "def cleanup():\n",
        "    \"\"\"Remove all generated files.\"\"\"\n",
        "    dirs_to_remove = ['output', 'cache', 'logs']\n",
        "    \n",
        "    for dir_name in dirs_to_remove:\n",
        "        dir_path = PROJECT_DIR / dir_name\n",
        "        if dir_path.exists():\n",
        "            shutil.rmtree(dir_path)\n",
        "            print(f\"Removed: {dir_path}\")\n",
        "    \n",
        "    print(\"Cleanup complete!\")\n",
        "\n",
        "# Uncomment to run cleanup\n",
        "# cleanup()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "In this notebook, we covered:\n",
        "\n",
        "1. **Installation** of GraphRAG toolkit\n",
        "2. **Configuration** of LLM and embedding models\n",
        "3. **Project setup** with proper directory structure\n",
        "4. **Document indexing** to build the knowledge graph\n",
        "5. **Querying** using local and global search methods\n",
        "6. **Exploration** of extracted entities and relationships\n",
        "7. **Visualization** of the knowledge graph\n",
        "\n",
        "## Resources\n",
        "\n",
        "- [GraphRAG Documentation](https://microsoft.github.io/graphrag/)\n",
        "- [GraphRAG GitHub Repository](https://github.com/microsoft/graphrag)\n",
        "- [GraphRAG Research Paper](https://arxiv.org/abs/2404.16130)\n",
        "\n",
        "## Tips\n",
        "\n",
        "- Use **Local Search** for specific entity lookups\n",
        "- Use **Global Search** for summarization and thematic questions\n",
        "- Adjust `chunk_size` based on your document structure\n",
        "- Consider using `gpt-4o` for better extraction quality\n",
        "- Monitor API costs during indexing of large document sets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
